{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://githubtocolab.com/giswqs/geemap/blob/master/examples/notebooks/46_local_rf_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>\n",
    "\n",
    "Uncomment the following line to install [geemap](https://geemap.org) if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geemap scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use locally trained machine learning models with GEE\n",
    "\n",
    "This notebook illustrates how to train a random forest (or any other ensemble tree estimator) locally using scikit-learn, convert the estimator into a string representation that Earth Engine can interpret, and how to apply the machine learning model with EE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import pandas as pd\n",
    "\n",
    "from geemap import ml\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, recall_score, accuracy_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=ZudJBYIMOLefiZRbQByy0jlvx3Zg8m-_chkqfsMZfdE&code_challenge_method=S256>https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=ZudJBYIMOLefiZRbQByy0jlvx3Zg8m-_chkqfsMZfdE&code_challenge_method=S256</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you\n",
       "        should paste in the box below</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter verification code: 4/1AX4XfWhC688Dh9LOS6DrWAnjbZoDkGOXVGb39MYIr4krEwJWmGLjibjlVg0\n",
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "geemap.ee_initialize()\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model locally using scikit-learn\n",
    "\n",
    "In this demo, we are going to use the training data from [here](https://github.com/giswqs/geemap/blob/master/examples/data/rf_example.csv). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the feature table to train our RandomForest model\n",
    "# data taken from ee.FeatureCollection('GOOGLE/EE/DEMOS/demo_landcover_labels')\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/giswqs/geemap/master/examples/data/rf_example.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>landcover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.139846</td>\n",
       "      <td>0.114738</td>\n",
       "      <td>0.109982</td>\n",
       "      <td>0.119542</td>\n",
       "      <td>0.125795</td>\n",
       "      <td>0.105720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.130316</td>\n",
       "      <td>0.109207</td>\n",
       "      <td>0.107499</td>\n",
       "      <td>0.140210</td>\n",
       "      <td>0.132006</td>\n",
       "      <td>0.108497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.146690</td>\n",
       "      <td>0.135766</td>\n",
       "      <td>0.146550</td>\n",
       "      <td>0.225686</td>\n",
       "      <td>0.218105</td>\n",
       "      <td>0.167111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.119413</td>\n",
       "      <td>0.108924</td>\n",
       "      <td>0.105196</td>\n",
       "      <td>0.144868</td>\n",
       "      <td>0.159775</td>\n",
       "      <td>0.122056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.155492</td>\n",
       "      <td>0.139932</td>\n",
       "      <td>0.137486</td>\n",
       "      <td>0.151377</td>\n",
       "      <td>0.153771</td>\n",
       "      <td>0.133134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.117331</td>\n",
       "      <td>0.092176</td>\n",
       "      <td>0.062548</td>\n",
       "      <td>0.020362</td>\n",
       "      <td>0.005813</td>\n",
       "      <td>0.004047</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.118353</td>\n",
       "      <td>0.093785</td>\n",
       "      <td>0.060253</td>\n",
       "      <td>0.020083</td>\n",
       "      <td>0.007317</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.123362</td>\n",
       "      <td>0.095831</td>\n",
       "      <td>0.069663</td>\n",
       "      <td>0.027320</td>\n",
       "      <td>0.011386</td>\n",
       "      <td>0.008357</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.122907</td>\n",
       "      <td>0.100083</td>\n",
       "      <td>0.079527</td>\n",
       "      <td>0.024564</td>\n",
       "      <td>0.008570</td>\n",
       "      <td>0.006321</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.119945</td>\n",
       "      <td>0.097548</td>\n",
       "      <td>0.066974</td>\n",
       "      <td>0.021062</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          B2        B3        B4        B5        B6        B7  landcover\n",
       "0   0.139846  0.114738  0.109982  0.119542  0.125795  0.105720          0\n",
       "1   0.130316  0.109207  0.107499  0.140210  0.132006  0.108497          0\n",
       "2   0.146690  0.135766  0.146550  0.225686  0.218105  0.167111          0\n",
       "3   0.119413  0.108924  0.105196  0.144868  0.159775  0.122056          0\n",
       "4   0.155492  0.139932  0.137486  0.151377  0.153771  0.133134          0\n",
       "..       ...       ...       ...       ...       ...       ...        ...\n",
       "93  0.117331  0.092176  0.062548  0.020362  0.005813  0.004047          2\n",
       "94  0.118353  0.093785  0.060253  0.020083  0.007317  0.004719          2\n",
       "95  0.123362  0.095831  0.069663  0.027320  0.011386  0.008357          2\n",
       "96  0.122907  0.100083  0.079527  0.024564  0.008570  0.006321          2\n",
       "97  0.119945  0.097548  0.066974  0.021062  0.006598  0.004311          2\n",
       "\n",
       "[98 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the names of the features (i.e. band names) and label\n",
    "# feature names used to extract out features and define what bands\n",
    "\n",
    "feature_names = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
    "label = \"landcover\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the features and labels into separate variables\n",
    "X = df[feature_names]\n",
    "y = df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a classifier and fit\n",
    "n_trees = 100 \n",
    "rf = ensemble.RandomForestClassifier(n_trees).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We perform hyper parameter tunning.\n",
    "param_grid = {'n_estimators': [300, 500],\n",
    "                     'max_depth':[50, 70],\n",
    "                     'min_samples_split': [5, 10],\n",
    "                     'min_samples_leaf': [2, 10]}\n",
    "#inner loop for tuning the hyperparameters\n",
    "cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "#outer loop for testing on holdout set\n",
    "cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "scorer = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': make_scorer(precision_score, average = 'macro'),\n",
    "           'recall': make_scorer(recall_score, average = 'macro'),\n",
    "           'f1_macro': make_scorer(f1_score, average = 'macro'),\n",
    "           'f1_weighted': make_scorer(f1_score, average = 'weighted')}\n",
    "clf = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, cv=cv_inner, random_state=42, n_iter=5)\n",
    "nested_score = cross_validate(clf, X=X, y=y, cv=cv_outer, scoring=scorer, return_estimator=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': 50,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 5,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 300,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': None,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#We print the optimal parameters for our model.\n",
    "from pprint import pprint\n",
    "pprint(model.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([17.90048337, 17.88489127, 17.65965772, 18.19124794, 18.12558866]),\n",
       " 'score_time': array([0.06671715, 0.07812881, 0.08868647, 0.06399179, 0.07067323]),\n",
       " 'estimator': [RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                     estimator=RandomForestClassifier(), n_iter=5,\n",
       "                     param_distributions={'max_depth': [50, 70],\n",
       "                                          'min_samples_leaf': [2, 10],\n",
       "                                          'min_samples_split': [5, 10],\n",
       "                                          'n_estimators': [300, 500]},\n",
       "                     random_state=42),\n",
       "  RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                     estimator=RandomForestClassifier(), n_iter=5,\n",
       "                     param_distributions={'max_depth': [50, 70],\n",
       "                                          'min_samples_leaf': [2, 10],\n",
       "                                          'min_samples_split': [5, 10],\n",
       "                                          'n_estimators': [300, 500]},\n",
       "                     random_state=42),\n",
       "  RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                     estimator=RandomForestClassifier(), n_iter=5,\n",
       "                     param_distributions={'max_depth': [50, 70],\n",
       "                                          'min_samples_leaf': [2, 10],\n",
       "                                          'min_samples_split': [5, 10],\n",
       "                                          'n_estimators': [300, 500]},\n",
       "                     random_state=42),\n",
       "  RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                     estimator=RandomForestClassifier(), n_iter=5,\n",
       "                     param_distributions={'max_depth': [50, 70],\n",
       "                                          'min_samples_leaf': [2, 10],\n",
       "                                          'min_samples_split': [5, 10],\n",
       "                                          'n_estimators': [300, 500]},\n",
       "                     random_state=42),\n",
       "  RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "                     estimator=RandomForestClassifier(), n_iter=5,\n",
       "                     param_distributions={'max_depth': [50, 70],\n",
       "                                          'min_samples_leaf': [2, 10],\n",
       "                                          'min_samples_split': [5, 10],\n",
       "                                          'n_estimators': [300, 500]},\n",
       "                     random_state=42)],\n",
       " 'test_accuracy': array([0.95, 0.95, 1.  , 1.  , 1.  ]),\n",
       " 'test_precision': array([0.95238095, 0.95833333, 1.        , 1.        , 1.        ]),\n",
       " 'test_recall': array([0.95238095, 0.94444444, 1.        , 1.        , 1.        ]),\n",
       " 'test_f1_macro': array([0.94871795, 0.94747475, 1.        , 1.        , 1.        ]),\n",
       " 'test_f1_weighted': array([0.95      , 0.94939394, 1.        , 1.        , 1.        ])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We evaluate the performance of our model with the optimal parameters.\n",
    "nested_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now fit our model with the optimum parameter to the data.\n",
    "rf= ensemble.RandomForestClassifier(bootstrap= True,\n",
    "ccp_alpha= 0.0,\n",
    "class_weight= None,\n",
    "criterion= 'gini',\n",
    "max_depth= 50,\n",
    "max_features= 'auto',\n",
    "max_leaf_nodes= None,\n",
    "max_samples= None,\n",
    " min_impurity_decrease= 0.0,\n",
    " min_samples_leaf= 2,\n",
    " min_samples_split= 5,\n",
    " min_weight_fraction_leaf= 0.0,\n",
    " n_estimators= 300,\n",
    " n_jobs= None,\n",
    " oob_score= False,\n",
    " random_state= None,\n",
    " verbose= 0,\n",
    " warm_start= False).fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert a sklearn classifier object to a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the estimator into a list of strings\n",
    "# this function also works with the ensemble.ExtraTrees estimator\n",
    "trees =  ml.rf_to_strings(rf,feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) root 57 9999 9999 (1.6179707257241982)\n",
      "  2) B7 <= 0.019053 22 0.0000 2 *\n",
      "  3) B7 > 0.019053 57 0.6589 2\n",
      "    6) B7 <= 0.125081 35 0.4911 1\n",
      "      12) B4 <= 0.102422 16 0.0000 1 *\n",
      "      13) B4 > 0.102422 3 0.0000 0 *\n",
      "    7) B7 > 0.125081 35 0.4911 1\n",
      "      14) B2 <= 0.134185 3 0.0000 1 *\n",
      "      15) B2 > 0.134185 13 0.0000 0 *\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the first tree to see the result\n",
    "print(trees[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) root 60 9999 9999 (1.7463389615768867)\n",
      "  2) B5 <= 0.063316 23 0.0000 2 *\n",
      "  3) B5 > 0.063316 60 0.6641 1\n",
      "    6) B4 <= 0.078633 16 0.0000 1 *\n",
      "    7) B4 > 0.078633 37 0.4942 1\n",
      "      14) B6 <= 0.198045 11 0.0000 0 *\n",
      "      15) B6 > 0.198045 21 0.2130 0\n",
      "        30) B3 <= 0.120434 3 0.0000 1 *\n",
      "        31) B3 > 0.120434 7 0.0000 0 *\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(trees[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of trees we converted should equal the number of trees we defined for the model\n",
    "len(trees) == n_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert sklearn classifier to GEE classifier\n",
    "\n",
    "At this point you can take the list of strings and save them locally to avoid training again. However, we want to use the model with EE so we need to create an ee.Classifier and persist the data on ee for best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ee classifier to use with ee objects from the trees\n",
    "ee_classifier = ml.strings_to_classifier(trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ee_classifier.getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify image using GEE classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a cloud-free Landsat 8 TOA composite (from raw imagery).\n",
    "l8 = ee.ImageCollection('LANDSAT/LC08/C01/T1');\n",
    "\n",
    "image = ee.Algorithms.Landsat.simpleComposite(\n",
    "  collection= l8.filterDate('2018-01-01', '2018-12-31'),\n",
    "  asFloat= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify the image using the classifier we created from the local training\n",
    "# note: here we select the feature_names from the image that way the classifier knows which bands to use\n",
    "classified = image.select(feature_names).classify(ee_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e919af2cdd40efa05bf843f5d6e91d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[37.75, -122.25], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(childâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display results\n",
    "legend_keys = ['vegetation', 'water', 'bare soil']\n",
    "legend_colors = ['#008000', '#0000FF', '#FF0000', ]\n",
    "Map = geemap.Map(center=(37.75,-122.25), zoom=11)\n",
    "\n",
    "Map.addLayer(image,{\"bands\": ['B7', 'B5', 'B3'], \"min\":0.05, \"max\": 0.55, \"gamma\":1.5}, 'image')\n",
    "Map.addLayer(classified, {\"min\": 0, \"max\": 2, \"palette\": ['red', 'green', 'blue']},'classification')\n",
    "Map.add_legend(legend_keys=legend_keys, legend_colors=legend_colors, position='bottomright')\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.1\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "from folium import plugins\n",
    "from IPython.display import Image\n",
    "import geopandas as gpd\n",
    "import json\n",
    "print(folium.__version__)\n",
    "from ipygee import*\n",
    "import math\n",
    "import pandas as pd\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.utils import to_time_series_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = ee.List.sequence(1,12)\n",
    "years = ee.List.sequence(2018, 2019)\n",
    "POI = ee.Geometry.Point([-122.2769, 37.7435])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MD_NDVI = ee.ImageCollection('LANDSAT/LC08/C01/T1_8DAY_NDVI').filterDate('2018-1-1','2019-12-31').filterBounds(POI).select('NDVI')\n",
    "modis_ndvi = MD_NDVI.median().clip(POI)\n",
    "mean_ndvi = MD_NDVI.mean().clip(POI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly(collection):\n",
    " img_coll = ee.ImageCollection([])\n",
    " for y in years.getInfo():\n",
    "  for m in months.getInfo():\n",
    "   filtered = collection.filter(ee.Filter.calendarRange(y,y,'year')).filter(ee.Filter.calendarRange(m, m, 'month'))\n",
    "   filtered = filtered.median()\n",
    "   img_coll = img_coll.merge(filtered.set('year', y).set('month', m).set('system:time_start',ee.Date.fromYMD(y, m, 1).getInfo()['value']))\n",
    " return img_coll\n",
    "Monthly_MD = monthly(MD_NDVI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ad8d26a65246b2bb45dff12519fce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<embed src=data:image/svg+xml;charset=utf-8;base64,PD94bWwgdmVyc2lvbj0nMS4wJyBlbmNvZGluZz0ndXRmLTgâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Point_1 = ee.Geometry.Point([-122.2776, 37.8181])\n",
    "MD_ndvi = chart.Image.series(**{'imageCollection': Monthly_MD,\n",
    "'region': Point_1,\n",
    "'reducer': ee.Reducer.mean(),\n",
    "'scale': 250,\n",
    "'xProperty': 'system:time_start'})\n",
    "MD_ndvi.renderWidget(width='80%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3c9f320fcc4c1688c0c1ae50894525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<embed src=data:image/svg+xml;charset=utf-8;base64,PD94bWwgdmVyc2lvbj0nMS4wJyBlbmNvZGluZz0ndXRmLTgâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Point_1 = ee.Geometry.Point([-122.5118, 37.8438])\n",
    "MD_ndvi = chart.Image.series(**{'imageCollection': Monthly_MD,\n",
    "'region': Point_1,\n",
    "'reducer': ee.Reducer.mean(),\n",
    "'scale': 500,\n",
    "'xProperty': 'system:time_start'})\n",
    "MD_ndvi.renderWidget(width='200%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05cfc9e1c7e40f2be1005b21e304738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<embed src=data:image/svg+xml;charset=utf-8;base64,PD94bWwgdmVyc2lvbj0nMS4wJyBlbmNvZGluZz0ndXRmLTgâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Point_1 = ee.Geometry.Point([-122.2769, 37.7435])\n",
    "MD_ndvi = chart.Image.series(**{'imageCollection': Monthly_MD,\n",
    "'region': Point_1,\n",
    "'reducer': ee.Reducer.mean(),\n",
    "'scale': 250,\n",
    "'xProperty': 'system:time_start'})\n",
    "MD_ndvi.renderWidget(width='80%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart.Image.series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1120aac0e4b04357a0036ebd5badc42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<embed src=data:image/svg+xml;charset=utf-8;base64,PD94bWwgdmVyc2lvbj0nMS4wJyBlbmNvZGluZz0ndXRmLTgâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Point_2 = ee.Geometry.Point([-122.5118, 37.8438])\n",
    "Point_1 = ee.Geometry.Point([-122.5118, 37.8438])\n",
    "MD_ndvi = chart.Image.series(**{'imageCollection': Monthly_MD,\n",
    "'region': Point_2, \n",
    "'reducer': ee.Reducer.mean(),\n",
    "'scale': 250,\n",
    "'xProperty': 'system:time_start'})\n",
    "MD_ndvi.renderWidget(width='80%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trees to the cloud\n",
    "\n",
    "Now we have the strings in a format that ee can use, we want to save it for later use. There is a function to export a list of tree strings to a feature collection. The feature collection will have a pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'users/mouliomngouh'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = geemap.ee_user_id()\n",
    "user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'users/mouliomngouh/random_forest_strings_test'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify asset id where to save trees\n",
    "# be sure to change <user_name> to your ee user name\n",
    "asset_id = user_id +  \"/random_forest_strings_test\"\n",
    "asset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kick off an export process so it will be saved to the ee asset\n",
    "ml.export_trees_to_fc(trees,asset_id)\n",
    "\n",
    "# this will kick off an export task, so wait a few minutes before moving on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the exported tree feature collection\n",
    "rf_fc = ee.FeatureCollection(asset_id)\n",
    "\n",
    "# convert it to a classifier, very similar to the `ml.trees_to_classifier` function\n",
    "another_classifier = ml.fc_to_classifier(rf_fc)\n",
    "\n",
    "# classify the image again but with the classifier from the persisted trees\n",
    "classified = image.select(feature_names).classify(another_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trees locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "out_csv = os.path.expanduser(\"~/Downloads/trees.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.trees_to_csv(trees, out_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_classifier = ml.csv_to_classifier(out_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified = image.select(feature_names).classify(another_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71752cfa07f74378aac0b2fecff26791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[37.75, -122.25], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(childâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display results\n",
    "# we should get the exact same results as before\n",
    "Map = geemap.Map(center=(37.75,-122.25), zoom=11)\n",
    "\n",
    "Map.addLayer(image,{\"bands\": ['B7', 'B5', 'B3'], \"min\":0.05, \"max\": 0.55, \"gamma\":1.5}, 'image')\n",
    "Map.addLayer(classified, {\"min\": 0, \"max\": 2, \"palette\": ['red', 'green', 'blue']},'classification')\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1872, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1534, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1355, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1872, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1534, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1355, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1872, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1534, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1355, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1872, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1534, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1355, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1872, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1534, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\Jean Paul\\.conda\\envs\\env_ishango\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1355, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [300, 500],\n",
    "                     'max_depth':[50, 70],\n",
    "                     'min_samples_split': [5, 10],\n",
    "                     'min_samples_leaf': [2, 10]}\n",
    "# inner loop for tuning the hyperparameters\n",
    "cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "# outer loop for testing on holdout set\n",
    "cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "clf = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, cv=cv_inner, random_state=42, n_iter=5)\n",
    "nested_score = cross_validate(clf, X=X, y=y, cv=cv_outer, scoring=('recall', 'precision', 'roc_auc'), return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sklearn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\JEANPA~1\\AppData\\Local\\Temp/ipykernel_2304/2618185485.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sklearn' is not defined"
     ]
    }
   ],
   "source": [
    "scorer = sklearn.metrics.make_scorer(sklearn.metrics.f1_score, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (Temp/ipykernel_2304/520681512.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\JEANPA~1\\AppData\\Local\\Temp/ipykernel_2304/520681512.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    'f1_weighted': make_scorer(f1_score, average = 'weighted')}\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "scorer = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': make_scorer(precision_score, average = 'macro'),\n",
    "           'recall': make_scorer(recall_score, average = 'macro'),\n",
    "           'f1_macro': make_scorer(f1_score, average = 'macro',\n",
    "           'f1_weighted': make_scorer(f1_score, average = 'weighted')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nested_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
